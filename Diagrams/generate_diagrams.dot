"""
Quranic Recitation AI System - Complete Graphviz Diagrams
Generate all architecture and workflow diagrams for the project

Install Graphviz first:
- Ubuntu/Debian: sudo apt-get install graphviz
- macOS: brew install graphviz
- Windows: Download from https://graphviz.org/download/

Install Python package: pip install graphviz
"""

from graphviz import Digraph

# ==============================================================================
# 1. HIGH-LEVEL SYSTEM ARCHITECTURE
# ==============================================================================

def create_system_architecture():
    """Overall system architecture showing main components"""
    dot = Digraph(comment='Quranic Recitation AI - System Architecture')
    dot.attr(rankdir='TB', splines='ortho', nodesep='0.8', ranksep='1.0')
    dot.attr('node', shape='box', style='rounded,filled', fillcolor='lightblue', 
             fontname='Arial', fontsize='11')
    
    # User Interface Layer
    dot.node('UI', 'User Interface\n(Mobile/Web App)', fillcolor='#FFE5B4')
    
    # API Gateway
    dot.node('API', 'API Gateway\n(FastAPI/Flask)', fillcolor='#E6E6FA')
    
    # Core Processing Components
    with dot.subgraph(name='cluster_core') as c:
        c.attr(label='Core Processing Layer', style='filled', color='lightgrey')
        c.node('ASR', 'Speech Recognition\nModule', fillcolor='#98FB98')
        c.node('TAJ', 'Tajweed Verification\nModule', fillcolor='#98FB98')
        c.node('MAK', 'Makhraj Analysis\nModule', fillcolor='#98FB98')
        c.node('ERR', 'Error Detection &\nCorrection Module', fillcolor='#98FB98')
    
    # Model Layer
    with dot.subgraph(name='cluster_models') as c:
        c.attr(label='AI Models Layer', style='filled', color='#F0F0F0')
        c.node('M1', 'CNN-LSTM-CTC\nASR Model', fillcolor='#FFB6C1')
        c.node('M2', 'EfficientNet\nTajweed Classifier', fillcolor='#FFB6C1')
        c.node('M3', 'LSTM\nMakhraj Detector', fillcolor='#FFB6C1')
    
    # Data Layer
    with dot.subgraph(name='cluster_data') as c:
        c.attr(label='Data & Storage Layer', style='filled', color='#FFFACD')
        c.node('DB', 'User Database\n(PostgreSQL)', fillcolor='#DDA0DD')
        c.node('STORE', 'Audio Storage\n(S3/Cloud)', fillcolor='#DDA0DD')
        c.node('REF', 'Reference Audio\nLibrary', fillcolor='#DDA0DD')
    
    # Connections
    dot.edge('UI', 'API', label='Audio Input')
    dot.edge('API', 'ASR')
    dot.edge('API', 'TAJ')
    dot.edge('API', 'MAK')
    
    dot.edge('ASR', 'M1')
    dot.edge('TAJ', 'M2')
    dot.edge('MAK', 'M3')
    
    dot.edge('M1', 'ERR', label='Transcription')
    dot.edge('M2', 'ERR', label='Rule Violations')
    dot.edge('M3', 'ERR', label='Pronunciation Errors')
    
    dot.edge('ERR', 'API', label='Feedback')
    dot.edge('API', 'UI', label='Results')
    
    dot.edge('API', 'DB', label='User Data', style='dashed')
    dot.edge('API', 'STORE', label='Audio Files', style='dashed')
    dot.edge('ERR', 'REF', label='Reference\nComparison', style='dashed')
    
    return dot

# ==============================================================================
# 2. DETAILED PROCESSING PIPELINE
# ==============================================================================

def create_processing_pipeline():
    """Detailed step-by-step processing pipeline"""
    dot = Digraph(comment='Processing Pipeline')
    dot.attr(rankdir='TB', splines='polyline', nodesep='0.6', ranksep='0.8')
    dot.attr('node', shape='box', style='filled', fontname='Arial', fontsize='10')
    
    # Input
    dot.node('START', 'User Records\nQuran Recitation', shape='ellipse', fillcolor='#90EE90')
    dot.node('INPUT', 'Audio Input\n(WAV/MP3)', fillcolor='#FFE5B4')
    
    # Preprocessing
    with dot.subgraph(name='cluster_preprocess') as c:
        c.attr(label='Preprocessing Stage', style='filled', color='lightblue')
        c.node('P1', 'Audio Normalization\n(16kHz sampling)', fillcolor='#E0FFFF')
        c.node('P2', 'Noise Reduction\n(Spectral Subtraction)', fillcolor='#E0FFFF')
        c.node('P3', 'Silence Removal\n(VAD)', fillcolor='#E0FFFF')
        c.node('P4', 'Segmentation\n(Verse/Ayah level)', fillcolor='#E0FFFF')
    
    # Feature Extraction
    with dot.subgraph(name='cluster_features') as c:
        c.attr(label='Feature Extraction', style='filled', color='#FFF0F5')
        c.node('F1', 'MFCC Extraction\n(13 coefficients)', fillcolor='#FFE4E1')
        c.node('F2', 'Mel-Spectrogram\nGeneration', fillcolor='#FFE4E1')
        c.node('F3', 'Delta & Delta-Delta\nFeatures', fillcolor='#FFE4E1')
    
    # Parallel Processing
    with dot.subgraph(name='cluster_parallel') as c:
        c.attr(label='Parallel Analysis', style='filled', color='#F0E68C')
        c.node('A1', 'ASR Transcription\n→ Arabic Text', fillcolor='#FFFFE0')
        c.node('A2', 'Tajweed Rule\nDetection', fillcolor='#FFFFE0')
        c.node('A3', 'Makhraj Point\nVerification', fillcolor='#FFFFE0')
        c.node('A4', 'Prosody Analysis\n(Pitch, Duration)', fillcolor='#FFFFE0')
    
    # Error Analysis
    with dot.subgraph(name='cluster_errors') as c:
        c.attr(label='Error Detection & Analysis', style='filled', color='#FFB6C1')
        c.node('E1', 'Compare with\nGround Truth', fillcolor='#FFC0CB')
        c.node('E2', 'Identify Error\nLocations', fillcolor='#FFC0CB')
        c.node('E3', 'Classify Error\nTypes', fillcolor='#FFC0CB')
        c.node('E4', 'Calculate\nConfidence Scores', fillcolor='#FFC0CB')
    
    # Feedback Generation
    with dot.subgraph(name='cluster_feedback') as c:
        c.attr(label='Feedback Generation', style='filled', color='#DDA0DD')
        c.node('FB1', 'Generate Detailed\nError Report', fillcolor='#EE82EE')
        c.node('FB2', 'Retrieve Reference\nAudio Clips', fillcolor='#EE82EE')
        c.node('FB3', 'Create Visual\nFeedback', fillcolor='#EE82EE')
        c.node('FB4', 'Calculate Overall\nScore', fillcolor='#EE82EE')
    
    # Output
    dot.node('OUTPUT', 'Present Results\nto User', fillcolor='#98FB98')
    dot.node('END', 'User Reviews\nFeedback', shape='ellipse', fillcolor='#90EE90')
    
    # Flow connections
    dot.edge('START', 'INPUT')
    dot.edge('INPUT', 'P1')
    dot.edge('P1', 'P2')
    dot.edge('P2', 'P3')
    dot.edge('P3', 'P4')
    
    dot.edge('P4', 'F1')
    dot.edge('P4', 'F2')
    dot.edge('F1', 'F3')
    
    dot.edge('F1', 'A1')
    dot.edge('F2', 'A2')
    dot.edge('F3', 'A3')
    dot.edge('F2', 'A4')
    
    dot.edge('A1', 'E1')
    dot.edge('A2', 'E1')
    dot.edge('A3', 'E1')
    dot.edge('A4', 'E1')
    
    dot.edge('E1', 'E2')
    dot.edge('E2', 'E3')
    dot.edge('E3', 'E4')
    
    dot.edge('E4', 'FB1')
    dot.edge('E4', 'FB2')
    dot.edge('E4', 'FB3')
    dot.edge('E4', 'FB4')
    
    dot.edge('FB1', 'OUTPUT')
    dot.edge('FB2', 'OUTPUT')
    dot.edge('FB3', 'OUTPUT')
    dot.edge('FB4', 'OUTPUT')
    
    dot.edge('OUTPUT', 'END')
    
    return dot

# ==============================================================================
# 3. ASR MODEL ARCHITECTURE (CNN-LSTM-CTC)
# ==============================================================================

def create_asr_architecture():
    """Detailed ASR model architecture"""
    dot = Digraph(comment='ASR Model Architecture')
    dot.attr(rankdir='TB', nodesep='0.5', ranksep='0.6')
    dot.attr('node', shape='box', style='filled', fontname='Arial', fontsize='10')
    
    # Input
    dot.node('IN', 'Audio Input\n(Waveform)', shape='cylinder', fillcolor='#FFE5B4')
    dot.node('SPEC', 'Mel-Spectrogram\n(80 bins × T frames)', fillcolor='#E0FFFF')
    
    # CNN Layers
    with dot.subgraph(name='cluster_cnn') as c:
        c.attr(label='Convolutional Layers', style='filled', color='#E6F2FF')
        c.node('CNN1', 'Conv2D Layer 1\n(32 filters, 3×3)\nReLU + BatchNorm', fillcolor='#B0E0E6')
        c.node('POOL1', 'MaxPooling2D\n(2×2)', fillcolor='#ADD8E6')
        c.node('CNN2', 'Conv2D Layer 2\n(64 filters, 3×3)\nReLU + BatchNorm', fillcolor='#B0E0E6')
        c.node('POOL2', 'MaxPooling2D\n(2×2)', fillcolor='#ADD8E6')
        c.node('CNN3', 'Conv2D Layer 3\n(128 filters, 3×3)\nReLU + BatchNorm', fillcolor='#B0E0E6')
    
    # Reshape
    dot.node('RESHAPE', 'Reshape to\nSequence Format\n(T × Features)', fillcolor='#FFE4E1')
    
    # LSTM Layers
    with dot.subgraph(name='cluster_lstm') as c:
        c.attr(label='Recurrent Layers', style='filled', color='#FFF0F5')
        c.node('LSTM1', 'BiLSTM Layer 1\n(256 units)\nDropout: 0.3', fillcolor='#FFB6C1')
        c.node('LSTM2', 'BiLSTM Layer 2\n(256 units)\nDropout: 0.3', fillcolor='#FFB6C1')
        c.node('LSTM3', 'BiLSTM Layer 3\n(256 units)\nDropout: 0.3', fillcolor='#FFB6C1')
    
    # Attention
    dot.node('ATT', 'Attention Mechanism\n(Multi-Head)', fillcolor='#DDA0DD')
    
    # Output Layers
    with dot.subgraph(name='cluster_output') as c:
        c.attr(label='Output Processing', style='filled', color='#F0E68C')
        c.node('DENSE', 'Dense Layer\n(512 units)\nReLU', fillcolor='#FFFFE0')
        c.node('SOFTMAX', 'Softmax Layer\n(Arabic chars + space)', fillcolor='#FFFFE0')
    
    # CTC Loss
    dot.node('CTC', 'CTC Loss\n(Sequence Alignment)', fillcolor='#FF6B6B', fontcolor='white')
    
    # Final Output
    dot.node('OUT', 'Arabic Text\nTranscription', shape='cylinder', fillcolor='#90EE90')
    
    # Connections
    dot.edge('IN', 'SPEC')
    dot.edge('SPEC', 'CNN1')
    dot.edge('CNN1', 'POOL1')
    dot.edge('POOL1', 'CNN2')
    dot.edge('CNN2', 'POOL2')
    dot.edge('POOL2', 'CNN3')
    dot.edge('CNN3', 'RESHAPE')
    dot.edge('RESHAPE', 'LSTM1')
    dot.edge('LSTM1', 'LSTM2')
    dot.edge('LSTM2', 'LSTM3')
    dot.edge('LSTM3', 'ATT')
    dot.edge('ATT', 'DENSE')
    dot.edge('DENSE', 'SOFTMAX')
    dot.edge('SOFTMAX', 'CTC', label='Training')
    dot.edge('SOFTMAX', 'OUT', label='Inference')
    
    return dot

# ==============================================================================
# 4. TAJWEED RULE VERIFICATION ARCHITECTURE
# ==============================================================================

def create_tajweed_architecture():
    """Tajweed rule classification model"""
    dot = Digraph(comment='Tajweed Verification Architecture')
    dot.attr(rankdir='TB', nodesep='0.5', ranksep='0.7')
    dot.attr('node', shape='box', style='filled', fontname='Arial', fontsize='10')
    
    # Input
    dot.node('IN', 'Audio Segment\n(2-5 seconds)', shape='cylinder', fillcolor='#FFE5B4')
    
    # Feature Extraction
    with dot.subgraph(name='cluster_feat') as c:
        c.attr(label='Feature Extraction', style='filled', color='#E0FFFF')
        c.node('MFCC', 'MFCC Features\n(13 coefficients)', fillcolor='#B0E0E6')
        c.node('DELTA', 'Delta Features\n(1st & 2nd order)', fillcolor='#B0E0E6')
        c.node('MEL', 'Mel-Spectrogram\n(128 bins)', fillcolor='#B0E0E6')
    
    # Parallel Model Branches
    with dot.subgraph(name='cluster_models') as c:
        c.attr(label='Rule-Specific Models', style='filled', color='#FFF0F5')
        
        # Al-Mad Model
        with c.subgraph(name='cluster_mad') as s:
            s.attr(label='Al-Mad (Prolongation)', style='filled', color='#FFE4E1')
            s.node('MAD1', 'LSTM\n(128 units)', fillcolor='#FFC0CB')
            s.node('MAD2', 'Dense\n(64 units)', fillcolor='#FFC0CB')
            s.node('MAD_OUT', 'Binary Output\n(Correct/Wrong)', fillcolor='#FFB6C1')
        
        # Ghunnah Model
        with c.subgraph(name='cluster_ghun') as s:
            s.attr(label='Ghunnah (Nasal)', style='filled', color='#FFE4E1')
            s.node('GHUN1', 'LSTM\n(128 units)', fillcolor='#FFC0CB')
            s.node('GHUN2', 'Dense\n(64 units)', fillcolor='#FFC0CB')
            s.node('GHUN_OUT', 'Binary Output\n(Correct/Wrong)', fillcolor='#FFB6C1')
        
        # Qalqalah Model
        with c.subgraph(name='cluster_qal') as s:
            s.attr(label='Qalqalah (Echo)', style='filled', color='#FFE4E1')
            s.node('QAL1', 'LSTM\n(128 units)', fillcolor='#FFC0CB')
            s.node('QAL2', 'Dense\n(64 units)', fillcolor='#FFC0CB')
            s.node('QAL_OUT', 'Binary Output\n(Correct/Wrong)', fillcolor='#FFB6C1')
    
    # Aggregation
    dot.node('AGG', 'Results Aggregation\n& Error Localization', fillcolor='#DDA0DD')
    
    # Output
    dot.node('OUT', 'Tajweed Report\n(Rule-by-Rule)', shape='note', fillcolor='#90EE90')
    
    # Connections
    dot.edge('IN', 'MFCC')
    dot.edge('IN', 'MEL')
    dot.edge('MFCC', 'DELTA')
    
    dot.edge('DELTA', 'MAD1')
    dot.edge('DELTA', 'GHUN1')
    dot.edge('MEL', 'QAL1')
    
    dot.edge('MAD1', 'MAD2')
    dot.edge('MAD2', 'MAD_OUT')
    
    dot.edge('GHUN1', 'GHUN2')
    dot.edge('GHUN2', 'GHUN_OUT')
    
    dot.edge('QAL1', 'QAL2')
    dot.edge('QAL2', 'QAL_OUT')
    
    dot.edge('MAD_OUT', 'AGG')
    dot.edge('GHUN_OUT', 'AGG')
    dot.edge('QAL_OUT', 'AGG')
    
    dot.edge('AGG', 'OUT')
    
    return dot

# ==============================================================================
# 5. DATA FLOW DIAGRAM
# ==============================================================================

def create_data_flow():
    """Data flow through the system"""
    dot = Digraph(comment='Data Flow Diagram')
    dot.attr(rankdir='LR', nodesep='1.0', ranksep='1.5')
    dot.attr('node', fontname='Arial', fontsize='10')
    
    # External Entities
    dot.node('USER', 'User/Student', shape='box3d', fillcolor='#FFE5B4', style='filled')
    dot.node('TEACHER', 'Tajweed Expert\n(for validation)', shape='box3d', fillcolor='#FFE5B4', style='filled')
    
    # Processes
    dot.node('P1', '1.0\nAudio Input\nProcessing', shape='circle', fillcolor='#E0FFFF', 
             style='filled', width='1.5', height='1.5')
    dot.node('P2', '2.0\nAI Model\nInference', shape='circle', fillcolor='#E0FFFF', 
             style='filled', width='1.5', height='1.5')
    dot.node('P3', '3.0\nError Analysis\n& Correction', shape='circle', fillcolor='#E0FFFF', 
             style='filled', width='1.5', height='1.5')
    dot.node('P4', '4.0\nFeedback\nGeneration', shape='circle', fillcolor='#E0FFFF', 
             style='filled', width='1.5', height='1.5')
    
    # Data Stores
    dot.node('D1', 'User Audio\nDatabase', shape='cylinder', fillcolor='#FFB6C1', style='filled')
    dot.node('D2', 'AI Models\nRepository', shape='cylinder', fillcolor='#FFB6C1', style='filled')
    dot.node('D3', 'Reference Audio\nLibrary', shape='cylinder', fillcolor='#FFB6C1', style='filled')
    dot.node('D4', 'User Progress\nDatabase', shape='cylinder', fillcolor='#FFB6C1', style='filled')
    
    # Data flows
    dot.edge('USER', 'P1', label='Audio\nRecitation')
    dot.edge('P1', 'D1', label='Store Audio')
    dot.edge('P1', 'P2', label='Preprocessed\nAudio')
    
    dot.edge('D2', 'P2', label='Load Models')
    dot.edge('P2', 'P3', label='Predictions')
    
    dot.edge('D3', 'P3', label='Reference\nData')
    dot.edge('P3', 'P4', label='Error Report')
    
    dot.edge('P4', 'D4', label='Update\nProgress')
    dot.edge('D4', 'P4', label='Historical\nData')
    
    dot.edge('P4', 'USER', label='Feedback &\nCorrections')
    
    dot.edge('TEACHER', 'D2', label='Model\nValidation', style='dashed')
    dot.edge('TEACHER', 'D3', label='Expert\nRecitations', style='dashed')
    
    return dot

# ==============================================================================
# 6. PROJECT PHASES TIMELINE
# ==============================================================================

def create_project_timeline():
    """Project implementation timeline"""
    dot = Digraph(comment='Project Timeline')
    dot.attr(rankdir='TB', nodesep='0.8', ranksep='0.5')
    dot.attr('node', shape='box', style='filled,rounded', fontname='Arial', fontsize='10')
    
    # Phases
    dot.node('START', 'Project Start', shape='ellipse', fillcolor='#90EE90')
    
    with dot.subgraph(name='cluster_p1') as c:
        c.attr(label='Phase 1: Research & Data (Weeks 1-3)', style='filled', color='#E0FFFF')
        c.node('P1_1', 'Dataset Collection\n(QDAT, Ar-DAD)', fillcolor='#B0E0E6')
        c.node('P1_2', 'Literature Review', fillcolor='#B0E0E6')
        c.node('P1_3', 'Data Preprocessing\n& Augmentation', fillcolor='#B0E0E6')
        c.node('P1_4', 'Tajweed Expert\nConsultation', fillcolor='#B0E0E6')
    
    with dot.subgraph(name='cluster_p2') as c:
        c.attr(label='Phase 2: Model Development (Weeks 4-10)', style='filled', color='#FFF0F5')
        c.node('P2_1', 'ASR Model\nTraining', fillcolor='#FFB6C1')
        c.node('P2_2', 'Tajweed Classifier\nTraining', fillcolor='#FFB6C1')
        c.node('P2_3', 'Makhraj Detector\nTraining', fillcolor='#FFB6C1')
        c.node('P2_4', 'Model Evaluation\n& Tuning', fillcolor='#FFB6C1')
    
    with dot.subgraph(name='cluster_p3') as c:
        c.attr(label='Phase 3: System Integration (Weeks 11-13)', style='filled', color='#F0E68C')
        c.node('P3_1', 'Pipeline Integration', fillcolor='#FFFFE0')
        c.node('P3_2', 'API Development', fillcolor='#FFFFE0')
        c.node('P3_3', 'Error Detection\nModule', fillcolor='#FFFFE0')
        c.node('P3_4', 'Feedback System', fillcolor='#FFFFE0')
    
    with dot.subgraph(name='cluster_p4') as c:
        c.attr(label='Phase 4: Application Dev (Weeks 14-16)', style='filled', color='#DDA0DD')
        c.node('P4_1', 'Frontend\nDevelopment', fillcolor='#EE82EE')
        c.node('P4_2', 'Backend\nIntegration', fillcolor='#EE82EE')
        c.node('P4_3', 'Database Setup', fillcolor='#EE82EE')
        c.node('P4_4', 'UI/UX Design', fillcolor='#EE82EE')
    
    with dot.subgraph(name='cluster_p5') as c:
        c.attr(label='Phase 5: Testing & Deploy (Weeks 17-18)', style='filled', color='#FFE5B4')
        c.node('P5_1', 'Unit Testing', fillcolor='#FFDAB9')
        c.node('P5_2', 'User Beta Testing', fillcolor='#FFDAB9')
        c.node('P5_3', 'Performance\nOptimization', fillcolor='#FFDAB9')
        c.node('P5_4', 'Deployment', fillcolor='#FFDAB9')
    
    dot.node('END', 'Project Complete\n(MVP Ready)', shape='ellipse', fillcolor='#90EE90')
    
    # Sequential flow
    dot.edge('START', 'P1_1')
    dot.edge('P1_1', 'P1_2')
    dot.edge('P1_2', 'P1_3')
    dot.edge('P1_3', 'P1_4')
    
    dot.edge('P1_4', 'P2_1')
    dot.edge('P2_1', 'P2_2')
    dot.edge('P2_2', 'P2_3')
    dot.edge('P2_3', 'P2_4')
    
    dot.edge('P2_4', 'P3_1')
    dot.edge('P3_1', 'P3_2')
    dot.edge('P3_2', 'P3_3')
    dot.edge('P3_3', 'P3_4')
    
    dot.edge('P3_4', 'P4_1')
    dot.edge('P4_1', 'P4_2')
    dot.edge('P4_2', 'P4_3')
    dot.edge('P4_3', 'P4_4')
    
    dot.edge('P4_4', 'P5_1')
    dot.edge('P5_1', 'P5_2')
    dot.edge('P5_2', 'P5_3')
    dot.edge('P5_3', 'P5_4')
    
    dot.edge('P5_4', 'END')
    
    return dot

# ==============================================================================
# 7. ERROR DETECTION & CORRECTION WORKFLOW
# ==============================================================================

def create_error_workflow():
    """Detailed error detection and correction process"""
    dot = Digraph(comment='Error Detection Workflow')
    dot.attr(rankdir='TB', nodesep='0.6', ranksep='0.7')
    dot.attr('node', shape='box', style='filled', fontname='Arial', fontsize='10')
    
    dot.node('INPUT', 'User Recitation\n+ AI Analysis Results', fillcolor='#FFE5B4')
    
    # Error Detection
    with dot.subgraph(name='cluster_detect') as c:
        c.attr(label='Error Detection', style='filled', color='#E0FFFF')
        c.node('D1', 'Compare Transcription\nwith Quran Text', fillcolor='#B0E0E6')
        c.node('D2', 'Check Tajweed\nRule Violations', fillcolor='#B0E0E6')
        c.node('D3', 'Verify Makhraj\nPoints', fillcolor='#B0E0E6')
        c.node('D4', 'Analyze Prosody\n(Pitch, Duration)', fillcolor='#B0E0E6')
    
    # Error Classification
    with dot.subgraph(name='cluster_classify') as c:
        c.attr(label='Error Classification', style='filled', color='#FFF0F5')
        c.node('C1', 'Word-Level\nErrors', fillcolor='#FFE4E1')
        c.node('C2', 'Tajweed Rule\nErrors', fillcolor='#FFE4E1')
        c.node('C3', 'Pronunciation\nErrors', fillcolor='#FFE4E1')
        c.node('C4', 'Timing/Rhythm\nErrors', fillcolor='#FFE4E1')
    
    # Error Severity
    dot.node('SEV', 'Assign Severity\nLevels', shape='diamond', fillcolor='#DDA0DD')
    
    # Correction Generation
    with dot.subgraph(name='cluster_correct') as c:
        c.attr(label='Correction Generation', style='filled', color='#F0E68C')
        c.node('COR1', 'Retrieve Correct\nArabic Text', fillcolor='#FFFFE0')
        c.node('COR2', 'Find Reference\nAudio Clip', fillcolor='#FFFFE0')
        c.node('COR3', 'Generate Visual\nComparison', fillcolor='#FFFFE0')
        c.node('COR4', 'Provide Practice\nExercises', fillcolor='#FFFFE0')
    
    # Feedback
    with dot.subgraph(name='cluster_feedback') as c:
        c.attr(label='User Feedback', style='filled', color='#FFB6C1')
        c.node('F1', 'Error Location\n(Timestamp)', fillcolor='#FFC0CB')
        c.node('F2', 'Error Description\n(What went wrong)', fillcolor='#FFC0CB')
        c.node('F3', 'Correct Form\n(Audio + Visual)', fillcolor='#FFC0CB')
        c.node('F4', 'Improvement Tips', fillcolor='#FFC0CB')
    
    dot.node('OUTPUT', 'Comprehensive\nFeedback Report', fillcolor='#90EE90')
    
    # Connections
    dot.edge('INPUT', 'D1')
    dot.edge('INPUT', 'D2')
    dot.edge('INPUT', 'D3')
    dot.edge('INPUT', 'D4')
    
    dot.edge('D1', 'C1')
    dot.edge('D2', 'C2')
    dot.edge('D3', 'C3')
    dot.edge('D4', 'C4')
    
    dot.edge('C1', 'SEV')
    dot.edge('C2', 'SEV')
    dot.edge('C3', 'SEV')
    dot.edge('C4', 'SEV')
    
    dot.edge('SEV', 'COR1', label='Critical')
    dot.edge('SEV', 'COR2', label='Major')
    dot.edge('SEV', 'COR3', label='Minor')
    dot.edge('SEV', 'COR4', label='All')
    
    dot.edge('COR1', 'F1')
    dot.edge('COR2', 'F2')
    dot.edge('COR3', 'F3')
    dot.edge('COR4', 'F4')
    
    dot.edge('F1', 'OUTPUT')
    dot.edge('F2', 'OUTPUT')
    dot.edge('F3', 'OUTPUT')
    dot.edge('F4', 'OUTPUT')
    
    return dot

# ==============================================================================
# MAIN EXECUTION - GENERATE ALL GRAPHS
# ==============================================================================

if __name__ == '__main__':
    print("Generating Quranic Recitation AI System Diagrams...")
    print("=" * 70)
    
    # Create output directory
    import os
    os.makedirs('diagrams', exist_ok=True)
    
    # Generate all diagrams
    diagrams = {
        '1_system_architecture': create_system_architecture(),
        '2_processing_pipeline': create_processing_pipeline(),
        '3_asr_architecture': create_asr_architecture(),
        '4_tajweed_architecture': create_tajweed_architecture(),
        '5_data_flow': create_data_flow(),
        '6_project_timeline': create_project_timeline(),
        '7_error_workflow': create_error_workflow()
    }
    
    # Save as both PNG and PDF
    for name, diagram in diagrams.items():
        print(f"\nGenerating: {name}")
        try:
            # Save as PNG
            diagram.render(f'diagrams/{name}', format='png', cleanup=True)
            print(f"  ✓ PNG saved: diagrams/{name}.png")
            
            # Save as PDF
            diagram.render(f'diagrams/{name}', format='pdf', cleanup=True)
            print(f"  ✓ PDF saved: diagrams/{name}.pdf")
            
            # Save source DOT file
            diagram.save(f'diagrams/{name}.dot')
            print(f"  ✓ DOT saved: diagrams/{name}.dot")
            
        except Exception as e:
            print(f"  ✗ Error: {str(e)}")
    
    print("\n" + "=" * 70)
    print("All diagrams generated successfully!")
    print(f"Location: {os.path.abspath('diagrams')}/")
    print("\nGenerated files:")
    print("  1. System Architecture - Overall system design")
    print("  2. Processing Pipeline - Detailed processing steps")
    print("  3. ASR Architecture - Speech recognition model")
    print("  4. Tajweed Architecture - Tajweed verification model")
    print("  5. Data Flow - How data moves through system")
    print("  6. Project Timeline - Implementation phases")
    print("  7. Error Workflow - Error detection process")